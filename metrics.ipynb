{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25743992",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "from six import iteritems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb3116c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap(metric, r_pred, r_true, user_ids, item_ids):\n",
    "    n = len(r_true)\n",
    "    values = []\n",
    "    for i in range(1000):\n",
    "        x = np.random.choice(n, size=n)\n",
    "        values.append(metric(r_pred[x], r_true[x], user_ids[x], item_ids[x]))\n",
    "    return values\n",
    "\n",
    "def rmse(r_pred, r_true, user_ids, item_ids):\n",
    "    return np.mean((r_pred - r_true)**2)**0.5\n",
    "\n",
    "def mae(r_pred, r_true, user_ids, item_ids):\n",
    "    return np.mean(np.abs(r_pred - r_true))\n",
    "\n",
    "def spearman(r_pred, r_true, user_ids, item_ids):\n",
    "    return spearmanr(r_pred, r_true)[0]\n",
    "\n",
    "def fcp(r_pred, r_true, user_ids, item_ids):\n",
    "    # https://github.com/NicolasHug/Surprise/blob/d29b255826506c95c4822fe633f1107354c3f6a5/surprise/accuracy.py\n",
    "    predictions = defaultdict(list)\n",
    "    for i in range(len(user_ids)):\n",
    "        predictions[int(user_ids[i])].append([r_true[i], r_pred[i]])\n",
    "    nc_u = defaultdict(int)\n",
    "    nd_u = defaultdict(int)\n",
    "    for u0, preds in iteritems(predictions):\n",
    "        if len(preds) == 1:\n",
    "            continue\n",
    "        for r0i, esti in preds:\n",
    "            for r0j, estj in preds:\n",
    "                if esti > estj and r0i > r0j:\n",
    "                    nc_u[u0] += 1\n",
    "                if esti >= estj and r0i < r0j:\n",
    "                    nd_u[u0] += 1\n",
    "    nc = np.mean(list(nc_u.values())) if nc_u else 0\n",
    "    nd = np.mean(list(nd_u.values())) if nd_u else 0\n",
    "    return nc / (nc + nd)\n",
    "\n",
    "def bpr(r_pred, r_true, user_ids, item_ids):\n",
    "    # rescale predictions to range 1-5\n",
    "    r_min, r_range = r_true.min(), r_true.max() - r_true.min()\n",
    "    r_pred, r_true = (r_pred - r_min)/r_range*4 + 1, (r_true - r_min)/r_range*4 + 1\n",
    "    # group input/output pairs by user_id\n",
    "    groups = {}\n",
    "    for i, user_id in enumerate(user_ids):\n",
    "        if user_id in groups:\n",
    "            groups[user_id].append((r_pred[i], r_true[i]))\n",
    "        else:\n",
    "            groups[user_id] = [(r_pred[i], r_true[i])]\n",
    "    # compute bpr\n",
    "    total, count = 0, 0\n",
    "    for user_id, group in groups.items():\n",
    "        for i in range(1, len(group)):\n",
    "            for j in range(i):\n",
    "                r_pred_i, r_true_i = group[i]\n",
    "                r_pred_j, r_true_j = group[j]\n",
    "                x = r_pred_i - r_pred_j if r_true_i > r_true_j else r_pred_j - r_pred_i\n",
    "                total, count = total + np.log(1/(1 + np.exp(-x))), count + 1\n",
    "    # normalize bpr by count and express as probability\n",
    "    return np.exp(total/count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5aee5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
